Databases:-

(Refer appendix section for foundations)

- To have data persistence, we need databases, otherwise the data we submit on our forms will disappear as we close our servers. Never in our worst nightmares we would want to see an empty userslist in our dream app.

SQL VS NOSQL:-
            Type     Organize    Lang       Scaling            Scehma
MongoDB - Document, Collections, NoSql, Primarily Horizontal, Flexible     
Postgres - Relational, tables, sql, Primarily Vertical, Rigid

In sql, we have relations between tables, and hence it becomes little hard to scale it Horizonatally, whereas, in nosql, related data is stored in a single object only and so it becomes easy for it to sclae Horizonatally.
Also sql is good with safety and has better querying capabilities, compare to mongo.
But, both them are learning from each other and trying to incorporate the best of both the worlds, in them. 

Scehemas and schemaless:-
- Scehmas make our database rigid. It resists evolution. if we need to change the schema, we sometimes have to stop the database and migrate entire data as per the new shcema in sql (eg, change the datatype of a certain column can be a tough job if we already have data). 
- While nosql dbs like MongoDB are schemaless. It doesnt force us to have Scehma but we can have schema at time of coding. 
But with rigid schema, we ofcourse have better safety. Our data cannot be corrupted easily by hackers.
Trade offs is between flexibility or predictability & safety with performance.


Which db to choose?
In our nasa project, the requirements we have is:
- data needs to be persist between restarts
- api needs to be stateless for cluster mode.

MongoDB stores the documents in bson format; a close cousin of json, Binary json. Built so that it can parse quickly, faster than json too. We dont need to store our js data (that comes with request as we are using js in client as nodejs), in forms of tables if we use mongo. 
MongoDB uses js as its internal scripting language.
sql works best with Relational data, wherein the data is related to each other. 
we can say that, when we are using js as a back-end lang, its preferred to use a noSql db as it would be easy to convert it into a similar format called bson, other than converting it into tables, which is comapratively pretty complex. Also we are starting out, so its not necessary for us to have a perfect structure right away, we need more flexibility as for now. Also we dont have much related data. so using sql wont give us much benefits.

Though with postgres, now it offers us json types also, where we can store data in json format, like we do in mongo. But thats what its core use. means, thats not what postgres is best for. It just has added this option for us to explore. 

MongoDB - best for unstructed data or where the structure will change often. 
sql - best when structure of data is known and well defined, eg banking information like card data. 

Its reliability on crud operations and on acid transactions. Acid transactions are a set of database transactions that are related to each other. The guarantees sql gives us on these transactions is really great. ACID (atomicity, consistency, isolation, durability).
durability - the data is persisted and will stay permanently.
atomicity - the data will be stored as a whole. Never a partial query is runned. Either whole or nothing. which is in general mongo also gives, but doesnt guarantees it as well as sql does.
These transactions are very powerful when we have a sequence of operations and need to either write the entire transaction at once or nothing at all. You see, its safe and reliable. 


=> Install mongoDb:-
- visit www.mongodb.com
- under products -> community server (cause its free)
- oh wait, shouldnt we use the mongo cloud service i.e. mongo Atlas.
- with server, the files will be stored in our local machine, with atlas, it will be hosted on cloud.
- So, lets start with mongo atlas.
- Sign up for free (in mongo atlas).
- On top rights, we can create an organization or a project.
- Name it anything you want.
- Now lets create a database.
- click on - build a cluster
- During build, select the default option and the free ones ofcourse, but do explore the options.
- Name the cluster as per your project. like nasaClsuter
- Once its done, start creating a new user.
- create a user -> set password auth -> give read & write rights to the user -> (we also have atlas admin rights, where the user can even create other users in our databse, but we wouldn't want that) Always remember - THE PRINCIPAL OF LEAST PRIVILEDGE. Give your users only those rights that are required to finsih the task - By cyber security agency.
Done with creating user? GOOODD!

- Then we have network access feature.
- Here, its a list of IP access list, means, a list of IP addresses that can have access to our databse.
- So, lets add one.
- when we are in production mode, we'll have to add the IP address of the server, our site is hosted on. Only that system, needs access to our database. 
- But for dev, we can selected allow access from anywhere option.

To connect to our databse, via node project:-
- Go to clusters -> click connect -> select connect via application (as we have our node project we need to connect to) -> select the node version -> copy the connection string (the weird url with our username and password)

Andddddd we are good to go!

for my jainikashah3@gmail.com a/c in mongo atlas, 
username is jainika
password is s6nsqPdI8bpKqJjD


=> To connect to mongo, we'll use mongoose, as its the most powrful & widely used library with mongoDB. 

connection string from mongo, ofc its diff for everyone
    mongodb+srv://admin-jainika:<password>@cluster0.xjmjly0.mongodb.net/?retryWrites=true&w=majority


// server.js
    const MONGO_URL = "mongodb+srv://admin-jainika:s6nsqPdI8bpKqJjD@cluster0.xjmjly0.mongodb.net/nasa?retryWrites=true&w=majority"

add this constant, the value is the connection string we get from the mongo atlas, replace the password field with actual password and nasa - as the database name.

- install mongo & mongoose:-
npm install mongodb
npm install mongoose


// server.js    
    const MONGO_URL = "mongodb+srv://admin-jainika:s6nsqPdI8bpKqJjD@cluster0.xjmjly0.mongodb.net/nasa?retryWrites=true&w=majority"

    mongoose.connection.once("open", () => {
        console.log("MongoDB Connection Ready!")
    })

    mongoose.connection.on("error", (err) => {
        console.error("Oops! we have an error!", err)
    })

    async function startServer(){
        await mongoose.connect(MONGO_URL);
        // .. all code later, first we connect mongoose.
    }

explanation: 
- here, first we set a constant of our connection string.
- then we set the mongoose.connection.once - we can write .on or .once, but as we know, that open event will be triggered only once during the start of our server, we are being explicit here, by adding .once.
- open event will be triggered when our connection with mongo db is ready.
- then we have error event, which ofcourse could be triggered multiple times, everytime we get an error basically. so use .on and console.error is just for browser to know that its an error. 
- last we connect mongoose.connect with our connection string, right before we add any other code in start server function. as we want to connnect to mongoose at first.


=> Object modeling:
- Mongoose give us object modeling capabilities.


=> Lets start creating schemas and models and documents and Collections for mongo database:

- Below is the schema of launches. There are quite a few datatypes we have in mongoose, can checkout teh docs, also multiple checks we can hvae on them like min, max, default, type, required, etc.
eg-
    flightNumber: {
        type: Number,
        max: 999,
        min: 1000,
        default: 100,
        required: true
    },

- If we add different type of data in the schema, lets if I add string in a number type of schema, mongoose wont allow us. OFC.

- Mongoose also supports adding foreign key concept, like eg- 

    property_name: {
        type: mongoose.ObjectId,
        ref: 'Planet'
    }
here, it will check, that the property_name is from the planet collection. Note that, it might not be preferrable rn, to use it, becuase its a feature of sql, and has many other features that supports this one. eg, I can join the two tables that has a foreign key relationship, but here, ofcourse it will check for the validation, but not really has features like join.
hence, it wont be much useful to us. Though we'll see later in course, how to use it nicely. 

- then we have array of strings, eg:
    customer: [ String ]

- Later, we export this schema via:-
    module.exports = mongoose.model('Launch', launchesSchema)
NOTE: 'Launch' is the word of the document we want in our mongo db. BUT, Mongoose will change it to lowercase and in plural format. Why? Becuase collection name in mongo, is always plural as it represents multiple documents in it. 
WE ALWAYS WRITE IN SINGULAR, and mongoose converts it into plural. eg, here it will store, "launches" in mongo db.


// final launches.mongo.js
    const mongoose = require('mongoose');
    const launchesSchema = new mongoose.Schema({
        flightNumber: {
            type: Number,
            required: true
        },
        launchDate: {
            type: Date,
            required: true
        },
        mission: {
            type: String,
            required: true 
        },
        rocket: {
            type: String,
            required: true
        },
        target: {
            type: String,
            required: true
        },
        upcoming: {
            type: Boolean,
            required: true
        },
        success: {
            type: Boolean,
            required: true,
            default: true
        },
        customer: [ String ]
    })

    module.exports = mongoose.model('Launch', launchesSchema)


// similar planet.mongo.js file
    const mongoose = require('mongoose');
    const planetsSchema = new mongoose.Schema({
        keplerName: {
            type: String,
            required: true
        },
    });

    module.exports = mongoose.model('Planet', planetsSchema)


Ok ok, now we see our file structure, and inside models folder, we have -
 a launches.model.js file
 a launches.mongo.js file

 a planet.mongo.js file
 a planet.model.js file

Doesnt this look confusing at first, that why we have model related code divided?
- well whats happening is, our model.js file is a general concept of MVC pattern. and our mongo.js file is specific to mongoose and mongodb related code.
in many projects we have only model related file. But what could happen here is, lets say we want to switch our databse to a different one. If we have a separate model.js file, that handles all the data manipulation related code, we wouldn't need to change our controllers or router files. 
Its always advisable to have these 2 separate for the separation of concerns approach.


- Advice time: A common mistake that new developers make, while changing code, is that they try to change too many things at once. And not doing it incrementally (step by step) and then testing at every step. Not doing so, this leads to a situation where new approach (code) not working and neither old one. Boom! You're frustrated again.
Always break things down, in smallest possible steps.


Okay, back to nasa :D 

Now, lets step by step see, how to add data in mongodb.

// planet.model.js  
    const planets = require('./planets.mongo')

    .on('data', async (data) => {
        // this will push data in our local memory.
        // if(isHabitualPlanet(data)) habitalPlanets.push(data)

        // this will push data in mongo db
        if(isHabitualPlanet(data)) await planets.create({
            keplerName: data.kepler_name
        })
    })

So, here, first we import the planets shcema object, we have created in mongo.js file. 
This planets object of mongoose has quite a many functions in it, like create, find, remove, etc.
To create data planets.create is used, and the exact format of data we have added in our planetsschema in model.js file, should be added here. like we are doing  keplerName: data.kepler_name.

But wait, this will surely create a new planet name in our mongodb. But this function (overall function) loadPlanetsData, is called in our app.js file, when the server is loaded. now everytime the server is loaded, we'll have this function calling.
This will result into duplicate data, as the csv file is same, the habitalPlanets list will always be the same, and we'll keep creating new documents in our collection with the same planets data.

What to do now?
Well, in mongoose we have an upsert function that will, update the data if already exist, or create data we not. woah! exactly what we want!

- To understand upsert, we need to know the find function of mongoose.
In mongoose, find function has a lot og varieties, like findById, findAndDelete, etc. (check docs)

Usecases of find method:

1. {} empty object returns all rows with no check.    
    return planets.find({})

2. find method takes an obj as a filter, Here, it will find data that has keplerName as kepler-62 f and will return those records,
    return planets.find({
         keplerName: 'kepler-62 f',
    })

3. find takes a second arg, where we can mention which fields we want in the result. lets say the document has 10 columns, and we only want 4 specific ones. 1 means add it in the result, 0 means delete. 
    return planets.find({
         keplerName: 'kepler-62 f',
    }, { 'keplerName': 1, 'keplerName': 0})
    
4. The field argument can also be a string, where no. of columns is separated by space. and - (minus) means exclude it and return all.    
    return planets.find({
        keplerName: 'kepler-62 f',
    }, 'keplerName anotherfield -toexcludefield' )

even greater than or equals to sign are allowed, check the docs. IT has quite a handy methods we would want during our development.


- Now lets come back to upsert operation:- here's the code:
    try {
        await planets.updateOne({
            keplerName: planet.kepler_name
        }, {
            keplerName: planet.kepler_name
        }, {
            upsert: true
        })
    }catch(err) { 
        console.error(`couldn't save planet ${err} `)
    }

to make an upsert operation, we need updateOne or many method.
updateOne, firs arg will be same as the find method, where the obj passed is taken as a filter. means, it will check if keplerName is already there in the data.
the second arg will replace the item , if already exist.
the third arg, if mentioned upsert as true, will add the record, if not exist.
do wrap it in try-catch block as db actions can be prone to error.
also, use asyn await, as all mongoose operations are asynchronous.


=> MongoDB Atlas:
- Here, under our cluster -> collections, we can edit, remove, filter our documents easily. can see the size, values, total no. of docs, etc. Atlas dashboard is very powerful and we can do a lot more in it. Keep exploring.
The filter thing works similar as find, and takes similar args.

- We can see, in our documents, there are 2 additional properties, _id and __v.
_id are called object ids in mongoose.
these ids are random value that are assigned to every document, and very unique.
why these ids are not auto-incremental like, 1 2 3 4.
That is because mongo, as we know, is designed best for horizontal scaling, and this doesnt look ideal, as on different servers, the value of _id should still persist the uniqueness.We shoudnt have duplicate ids in different machines also. 
guess what? via this id, we can also get the timestamp. Google out for mongo objectID to timestamp converter and paste your id, you'll get the timestamp(date+time) of when the document was created. hence, we dont need to additionally add the timestamp in documents, mogo anyways does it for us, pretty cool, isnt it?

__v
an added advanced version of mongoose (not mongo specifically).
This is used to keep track of version of the documents. eg, we changes our schema of a collection, and the new records will follow that schema, but you still want the old documents. here, we can increase the version of the document, and let our application (node app) later decides which data to use and how.
To do this same, in sql would be a tedious task. and such migration can also make your db down for a quite a while.

Ok to note: Never send such properties like _id and __v via api back in response.
To do so,

    return await planets.find({}, {
        "_id":0,
        "__v":0
    })

Phewwww! Tough Job, J.


Referential Integrity:
- Nothing just a fancy way of saying, foreign key concept. Well, its an imp concept and sql is prettyyyyy good at it, but nosql, Nope, its not that good.

Well, for us handle that in nosql, we have to add certain conditions, like find the whole data and check it manually.

Example:- Inside our launches model, wehre we are saving new launch, we made a check that whether the target (user input) is equal to any of our planet, then only move further, otherwise throw error.

    async function saveLaunch(data){
        const planet = await planets.findOne({
            keplerName: data.target
        })
        if(!planet){
            throw new Error('No matching planets found')
        }
        
        await launchesDatabase.updateOne({
            flightNumber: data.flightNumber,
        }, data, {
            upsert: true
        })
    }

- Okay, here come one more downsides of mongo.
- In sql, we hvae auto_increment thing, wherein the property will auto increment itself, well, in our mongo, there's no such thing.
(eg in postgres we have serial)

- well, if we search for auto_increment in mongo on google, there would be a ton of results, and to summarize them all, all of those results have a fairly complex algorithm to work with.
Why is it so hard for mongo to track the auto_increment value?
That is because its easy for us to have horizontal scaling in mongo. And as we know, there are chances of having multiple databases where our data is divided into. and well, which db will auto_increment it? No idea right. well, we could have it incrmeented in all databases, but then it should be in sync with all our databases and its a fairly added complexity in our mongo. And our mongo developers didnt like this much.

So, whats mongo's way?

// In our Example project, we need an auto increment value of flight number. So lets take that as an Example.
- here, what trick we do is, we sort the records, based on flight number field and put it in descending (by adding a minus sign), as findOne takes the first item from the list, if returned more than one record.
- we'll get the latest flight number added, and then we add increment it by 1, to get the incremented value.

    async function getLatestFlightNumber() {
        const latestLaunch = await launchesDatabase
        .findOne({})
        .sort('-flightNumber')

        if(!latestLaunch) return DEFAULT_FLIGHT_NUMBER

        return latestLaunch.flightNumber;
    }


=> When we make a post request and save the data in our mongo database, $setOnInsert function will automatically be added to our response. (Means we'll get an extra property in our response that we send back to FE).
This $setOnInsert function is runned when upsert operation is true, and only incase of when mongo inserts the document (rem, it can insert & update the document, for insert case, setOnInsert function is exeucted)
When it comes to sending data to FE, make sure to always send precise data, the data that is utmost required. Such functions can be an invite for hackers as it will them an idea that we are using mongo and other details as well. 
Rem, LESS IS BETTER (when comes to sending data to fe)
So, what to do?
well, we can replace updateOne function with finOneAndUpdate()
The parameters are same for both, the only diff is finOneAndUpdate will update the document and return the exact fields that we passed.
Ok, one IMP thing to remember.
In updateOne function, the second param that we send, which is the object that we want to sent to the mongo db, always rem. that obj will also be updated as the document in your mongo database. hence, the launch param, that we get from our request payload, is pass to the mongo server, and whichever way mongo updates the document in the db, it will update our local param obj as well.
Hence, updateOne keeps a setOnInsert function on documents in our db, and finOneAndUpdate doesnt. Thus we get setOnInsert property in updateOne function and not in our finOneAndUpdate function.

- If we console the data that mongo sends when we manipulate a document, eg performing updateOne function, it sends a quite a few data like, modified, ok, uptime, etc.







=> Testing:
- If we see, our test we created earlier, with jest and all, wont be working now.
That is because mongoose doesnt recommend using node with jest for testing, though a lot of applications still does it and there's nothing wrong it.
- If so, mongoose recommends to use node test env, in place of jest's default environment that is called jsDom.
To change this config, go to server folder -> package.json:
    "license": "...", // below this line
    "jest": {
        "testEnvironment": "node"
    }

Now, if we run our test files, it will no longer throw the warnings. (though some error will still be there).
Those errors are because, we have written our mongoose related code, in app.js and test/supertest related code in server.js. And so, jest doesnt find the code, and throws error.
What to do now? Re-write the code in server.js file?
But then what abt the DRY PRINCIPAL?
Well, we have to create a folder in src -> services -> mongo.js
And here, we'll take all the mongoose related code from app and export the same. Import it in app and test files.

